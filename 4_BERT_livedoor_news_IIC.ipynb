{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4_BERT_livedoor_news_IIC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c23bc5609d4d491782dc45cc84958a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be37ef3bddd8457096e1fe8523a347bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72ef4ed5e1784b44b0ed5e86a6ecd8b0",
              "IPY_MODEL_6383c45cf6f44683a573815b864314b6"
            ]
          }
        },
        "be37ef3bddd8457096e1fe8523a347bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72ef4ed5e1784b44b0ed5e86a6ecd8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7388cb06773442cb97b86d47b8c35491",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 479,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 479,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dea30453b0f4f7191530a8e1a66a78a"
          }
        },
        "6383c45cf6f44683a573815b864314b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_973e19ac9e61456faec704de3118c38c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 479/479 [00:25&lt;00:00, 18.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b7b513c94be4ba0b09800852bce8d2a"
          }
        },
        "7388cb06773442cb97b86d47b8c35491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dea30453b0f4f7191530a8e1a66a78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "973e19ac9e61456faec704de3118c38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b7b513c94be4ba0b09800852bce8d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "539274af44ff45d591d6c501d342b4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_072882b372d74cb0b691e5369370961a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_609d693110db4c84bbe115ed15c9c4b0",
              "IPY_MODEL_a9c3a93c2f4f49dfade7b35754f92807"
            ]
          }
        },
        "072882b372d74cb0b691e5369370961a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "609d693110db4c84bbe115ed15c9c4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24720e2902ac464cad86eba3448dae32",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445021143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445021143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d0594fac3aa494cb199d0519e63ff6f"
          }
        },
        "a9c3a93c2f4f49dfade7b35754f92807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0de069ed4f54ee0817137547e2254df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:10&lt;00:00, 40.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c9e715e0e084bbca5fbf47c2db81ff0"
          }
        },
        "24720e2902ac464cad86eba3448dae32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d0594fac3aa494cb199d0519e63ff6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0de069ed4f54ee0817137547e2254df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c9e715e0e084bbca5fbf47c2db81ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/BERT-Japanese/blob/main/4_BERT_livedoor_news_IIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYlVm0kpjx57"
      },
      "source": [
        "## 日本語BERTでlivedoorニュースを相互情報量最大化(IIC)でクラスタリング"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqIW6ar2Bm3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f59be6-4d8c-4f4d-ed93-32ce08b20b5a"
      },
      "source": [
        "# 乱数シードの固定\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED_VALUE = 1234  # これはなんでも良い\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
        "random.seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)\n",
        "torch.manual_seed(SEED_VALUE)  # PyTorchを使う場合\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc47f30bb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii-mqaAhCApI"
      },
      "source": [
        "### GPUの使用可能を確認\n",
        "\n",
        "画面上部のメニュー ランタイム > ランタイムのタイプを変更 で、 ノートブックの設定 を開く\n",
        "\n",
        "ハードウェアアクセラレータに GPU を選択し、 保存 する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8TJgawCB_Nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64486f0-80dc-4d1d-c467-6e87bab550e0"
      },
      "source": [
        "# GPUの使用確認：True or False\n",
        "torch.cuda.is_available()\n",
        "\n",
        "# TrueならGPU使用可能"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6dbVUfj1W-"
      },
      "source": [
        "## 準備1：livedoorニュースをダウンロードして、PyTorchのDataLoaderに変換\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vh0a49Gp-rS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfed408-bbc5-465d-d8aa-3354d4750a16"
      },
      "source": [
        "# Livedoorニュースのファイルをダウンロード\n",
        "! wget \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-03 06:25:07--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8855190 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘ldcc-20140209.tar.gz.4’\n",
            "\n",
            "ldcc-20140209.tar.g 100%[===================>]   8.44M  5.00MB/s    in 1.7s    \n",
            "\n",
            "2021-07-03 06:25:09 (5.00 MB/s) - ‘ldcc-20140209.tar.gz.4’ saved [8855190/8855190]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keY2WGdwjzLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118b1d58-d131-4840-80ca-33ff24d3a44f"
      },
      "source": [
        "# ファイルを解凍し、カテゴリー数と内容を確認\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "# 解凍\n",
        "tar = tarfile.open(\"ldcc-20140209.tar.gz\", \"r:gz\")\n",
        "tar.extractall(\"./data/livedoor/\")\n",
        "tar.close()\n",
        "\n",
        "# フォルダのファイルとディレクトリを確認\n",
        "files_folders = [name for name in os.listdir(\"./data/livedoor/text/\")]\n",
        "print(files_folders)\n",
        "\n",
        "# カテゴリーのフォルダのみを抽出\n",
        "categories = [name for name in os.listdir(\n",
        "    \"./data/livedoor/text/\") if os.path.isdir(\"./data/livedoor/text/\"+name)]\n",
        "\n",
        "print(\"カテゴリー数:\", len(categories))\n",
        "print(categories)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CHANGES.txt', 'livedoor-homme', 'it-life-hack', 'topic-news', 'movie-enter', 'smax', 'sports-watch', 'dokujo-tsushin', 'peachy', 'README.txt', 'kaden-channel']\n",
            "カテゴリー数: 9\n",
            "['livedoor-homme', 'it-life-hack', 'topic-news', 'movie-enter', 'smax', 'sports-watch', 'dokujo-tsushin', 'peachy', 'kaden-channel']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9BPGnm4mJua"
      },
      "source": [
        "# 本文を取得する前処理関数を定義\n",
        "\n",
        "\n",
        "def extract_main_txt(file_name):\n",
        "    with open(file_name) as text_file:\n",
        "        # 今回はタイトル行は外したいので、3要素目以降の本文のみ使用\n",
        "        text = text_file.readlines()[3:]\n",
        "\n",
        "        # 3要素目以降にも本文が入っている場合があるので、リストにして、後で結合させる\n",
        "        text = [sentence.strip() for sentence in text]  # 空白文字(スペースやタブ、改行)の削除\n",
        "        text = list(filter(lambda line: line != '', text))\n",
        "        text = ''.join(text)\n",
        "        text = text.translate(str.maketrans(\n",
        "            {'\\n': '', '\\t': '', '\\r': '', '\\u3000': ''}))  # 改行やタブ、全角スペースを消す\n",
        "        return text\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4CnfAGZmK24"
      },
      "source": [
        "# リストに前処理した本文と、カテゴリーのラベルを追加していく\n",
        "import glob\n",
        "\n",
        "list_text = []\n",
        "list_label = []\n",
        "\n",
        "for cat in categories:\n",
        "    text_files = glob.glob(os.path.join(\"./data/livedoor/text\", cat, \"*.txt\"))\n",
        "\n",
        "    # 前処理extract_main_txtを実施して本文を取得\n",
        "    body = [extract_main_txt(text_file) for text_file in text_files]\n",
        "\n",
        "    label = [cat] * len(body)  # bodyの数文だけカテゴリー名のラベルのリストを作成\n",
        "\n",
        "    list_text.extend(body)  # appendが要素を追加するのに対して、extendはリストごと追加する\n",
        "    list_label.extend(label)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJpQoYv3mMdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e84d78-dc83-42a3-ad0e-e940e11e3095"
      },
      "source": [
        "# pandasのDataFrameにする\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'text': list_text, 'label': list_label})\n",
        "\n",
        "# 大きさを確認しておく（7,376文章が存在）\n",
        "print(df.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7376, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCyHRxKZmPiG"
      },
      "source": [
        "# カテゴリーの辞書を作成\n",
        "dic_id2cat = dict(zip(list(range(len(categories))), categories))\n",
        "dic_cat2id = dict(zip(categories, list(range(len(categories)))))\n",
        "\n",
        "# DataFrameにカテゴリーindexの列を作成\n",
        "df[\"label_index\"] = df[\"label\"].map(dic_cat2id)\n",
        "\n",
        "# label列を消去し、text, indexの順番にする\n",
        "df = df.loc[:, [\"text\", \"label_index\"]]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl7A9wqgmT6I"
      },
      "source": [
        "# 順番をシャッフルする\n",
        "df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6SefmjxmWUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1597e947-605b-4b20-a59c-8ee51ef3367b"
      },
      "source": [
        "# tsvファイルで保存する\n",
        "\n",
        "# 全体の2割の文章数\n",
        "len_0_2 = len(df) // 5\n",
        "\n",
        "# 前から2割をテストデータとする\n",
        "df[:len_0_2].to_csv(\"./test.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df[:len_0_2].shape)\n",
        "\n",
        "# 前2割からを訓練&検証データとする\n",
        "df[len_0_2:].to_csv(\"./train_eval.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df[len_0_2:].shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1475, 2)\n",
            "(5901, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctr9cqijmY1w"
      },
      "source": [
        "# tsvファイルをダウンロードしたい場合\n",
        "from google.colab import files\n",
        "\n",
        "# ダウンロードする場合はコメントを外す\n",
        "# 少し時間がかかる（4MB）\n",
        "# files.download(\"./test.tsv\")\n",
        "\n",
        "\n",
        "# ダウンロードする場合はコメントを外す\n",
        "# 少し時間がかかる（18MB）\n",
        "# files.download(\"./train_eval.tsv\")\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRpWunm7mmoq"
      },
      "source": [
        "- LivedoorニュースをBERT用のDataLoaderにする\n",
        "- Hugginfaceのリポジトリの案内とは異なり、torchtextを使用した手法で実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQFouaGHmWXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7997e5-b252-4b75-dd21-652f7e100671"
      },
      "source": [
        "# MeCabとtransformersの用意\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3\n",
        "!pip install transformers==2.9.0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "swig is already the newest version (3.0.12-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: transformers==2.9.0 in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.0.45)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.1.96)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHH2uWP2B_Rs"
      },
      "source": [
        "!sudo cp /etc/mecabrc /usr/local/etc/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnF1Kqbpmr9Z"
      },
      "source": [
        "import torch\n",
        "import torchtext  # torchtextを使用\n",
        "from transformers.modeling_bert import BertModel\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
        "\n",
        "# 日本語BERTの分かち書き用tokenizerです\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(\n",
        "    'bert-base-japanese-whole-word-masking')\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g09HyOvcmt3g"
      },
      "source": [
        "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "\n",
        "max_length = 512  # 東北大学_日本語版の最大の単語数（サブワード数）は512\n",
        "\n",
        "\n",
        "def tokenizer_512(input_text):\n",
        "    \"\"\"torchtextのtokenizerとして扱えるように、512単語のpytorchでのencodeを定義。ここで[0]を指定し忘れないように\"\"\"\n",
        "    return tokenizer.encode(input_text, max_length=512, return_tensors='pt')[0]\n",
        "\n",
        "\n",
        "TEXT = torchtext.legacy.data.Field(sequential=True, tokenize=tokenizer_512, use_vocab=False, lower=False,\n",
        "                            include_lengths=True, batch_first=True, fix_length=max_length, pad_token=0)\n",
        "# 注意：tokenize=tokenizer.encodeと、.encodeをつけます。padding[PAD]のindexが0なので、0を指定します。\n",
        "\n",
        "LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# (注釈)：各引数を再確認\n",
        "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
        "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
        "# use_vocab：単語をボキャブラリーに追加するかどうか\n",
        "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
        "# include_length: 文章の単語数のデータを保持するか\n",
        "# batch_first：ミニバッチの次元を用意するかどうか\n",
        "# fix_length：全部の文章をfix_lengthと同じ長さになるように、paddingします\n",
        "# init_token, eos_token, pad_token, unk_token：文頭、文末、padding、未知語に対して、どんな単語を与えるかを指定\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd1nnQfDmvsw"
      },
      "source": [
        "# 各tsvファイルを読み込み、分かち書きをしてdatasetにします\n",
        "# 少し時間がかかります\n",
        "# train_eval：5901個、test：1475個\n",
        "dataset_train_eval, dataset_test = torchtext.legacy.data.TabularDataset.splits(\n",
        "    path='.', train='train_eval.tsv', test='test.tsv', format='tsv', fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIG7NxComxco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6143f5-78a8-44fd-e538-0c91fa975981"
      },
      "source": [
        "# torchtext.data.Datasetのsplit関数で訓練データと検証データを分ける\n",
        "# train_eval：5901個、test：1475個\n",
        "\n",
        "dataset_train, dataset_eval = dataset_train_eval.split(\n",
        "    split_ratio=1.0 - 1475/5901, random_state=random.seed(1234))\n",
        "\n",
        "# datasetの長さを確認してみる\n",
        "print(dataset_train.__len__())\n",
        "print(dataset_eval.__len__())\n",
        "print(dataset_test.__len__())\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4426\n",
            "1475\n",
            "1475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XitKKeEgmzTp"
      },
      "source": [
        "# DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "batch_size = 16  # BERTでは16、32あたりを使用する\n",
        "\n",
        "dl_train = torchtext.legacy.data.Iterator(\n",
        "    dataset_train, batch_size=batch_size, train=True)\n",
        "\n",
        "dl_eval = torchtext.legacy.data.Iterator(\n",
        "    dataset_eval, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "dl_test = torchtext.legacy.data.Iterator(\n",
        "    dataset_test, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": dl_train, \"val\": dl_eval}\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln5XJH3lm4MR"
      },
      "source": [
        "## 準備2：BERTでlivedoorニュースの記事をベクトル化する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFlvnI05a4xN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "c23bc5609d4d491782dc45cc84958a3e",
            "be37ef3bddd8457096e1fe8523a347bf",
            "72ef4ed5e1784b44b0ed5e86a6ecd8b0",
            "6383c45cf6f44683a573815b864314b6",
            "7388cb06773442cb97b86d47b8c35491",
            "6dea30453b0f4f7191530a8e1a66a78a",
            "973e19ac9e61456faec704de3118c38c",
            "2b7b513c94be4ba0b09800852bce8d2a",
            "539274af44ff45d591d6c501d342b4dd",
            "072882b372d74cb0b691e5369370961a",
            "609d693110db4c84bbe115ed15c9c4b0",
            "a9c3a93c2f4f49dfade7b35754f92807",
            "24720e2902ac464cad86eba3448dae32",
            "5d0594fac3aa494cb199d0519e63ff6f",
            "e0de069ed4f54ee0817137547e2254df",
            "2c9e715e0e084bbca5fbf47c2db81ff0"
          ]
        },
        "outputId": "9ac88e98-9449-47c8-c49f-d3ce776d69a4"
      },
      "source": [
        "from transformers.modeling_bert import BertModel\n",
        "\n",
        "# BERTの日本語学習済みパラメータのモデルです\n",
        "model = BertModel.from_pretrained('bert-base-japanese-whole-word-masking')\n",
        "model.eval()\n",
        "print('ネットワーク設定完了')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c23bc5609d4d491782dc45cc84958a3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=479.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "539274af44ff45d591d6c501d342b4dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445021143.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ネットワーク設定完了\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNaAXgiITFiw"
      },
      "source": [
        "# BERTでベクトル化する関数を定義\n",
        "\n",
        "\n",
        "def vectorize_with_bert(net, dataloader):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloader.batch_size\n",
        "\n",
        "    # データローダーからミニバッチを取り出すループ\n",
        "    for index, batch in enumerate(dataloader):\n",
        "        # batchはTextとLableの辞書オブジェクト\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        inputs = batch.Text[0].to(device)  # 文章\n",
        "        labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "        # 順伝搬（forward）計算\n",
        "        with torch.set_grad_enabled(False):\n",
        "\n",
        "            # Berに入力\n",
        "            result = net(inputs)\n",
        "\n",
        "            # sequence_outputの先頭の単語ベクトルを抜き出す\n",
        "            vec_0 = result[0]  # 最初の0がsequence_outputを示す\n",
        "            vec_0 = vec_0[:, 0, :]  # 全バッチ。先頭0番目の単語の全768要素\n",
        "            vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_size]に変換\n",
        "\n",
        "            # ベクトル化したデータをtorchリストにまとめる\n",
        "            if index == 0:\n",
        "                list_text = vec_0\n",
        "                list_label = labels\n",
        "            else:\n",
        "                list_text = torch.cat([list_text, vec_0], dim=0)\n",
        "                list_label = torch.cat([list_label, labels], dim=0)\n",
        "\n",
        "    return list_text, list_label\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfnH-gAmS75e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de95d5f7-00cd-43d3-d699-c5bfaa57fcd8"
      },
      "source": [
        "# DataLoaderをベクトル化版に変換\n",
        "# 少し時間がかかります5分弱\n",
        "\n",
        "list_text_train, list_label_train = vectorize_with_bert(model, dl_train)\n",
        "list_text_eval, list_label_eval = vectorize_with_bert(model, dl_eval)\n",
        "list_text_test, list_label_test = vectorize_with_bert(model, dl_test)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "使用デバイス： cuda:0\n",
            "-----start-------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Aq6sYxFF2ti"
      },
      "source": [
        "# torchのリストをDatasetに変換\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "dataset_bert_train = TensorDataset(\n",
        "    list_label_train.view(-1, 1), list_text_train)\n",
        "dataset_bert_eval = TensorDataset(list_label_eval.view(-1, 1), list_text_eval)\n",
        "dataset_bert_test = TensorDataset(list_label_test.view(-1, 1), list_text_test)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktNKYU_XK_3T"
      },
      "source": [
        "# Dataloaderにする\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 1024\n",
        "\n",
        "dl_bert_train = DataLoader(\n",
        "    dataset_bert_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "# drop_lastは最後のミニバッチがbatch_sizeに足りない場合は無視する\n",
        "\n",
        "dl_bert_eval = DataLoader(\n",
        "    dataset_bert_eval, batch_size=batch_size, shuffle=False)\n",
        "dl_bert_test = DataLoader(\n",
        "    dataset_bert_test, batch_size=batch_size, shuffle=False)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGA7Tm-CMHs1"
      },
      "source": [
        "## 準備3：IICのディープラーニングモデルを用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pgI08SsMJ-y"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "OVER_CLUSTRING_RATE = 10\n",
        "\n",
        "\n",
        "class NetIIC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetIIC, self).__init__()\n",
        "\n",
        "        # multi-headは今回しない\n",
        "        self.conv1 = nn.Conv1d(1, 400, kernel_size=768, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm1d(400)\n",
        "        self.conv2 = nn.Conv1d(1, 300, kernel_size=400, stride=1, padding=0)\n",
        "        self.bn2 = nn.BatchNorm1d(300)\n",
        "        self.conv3 = nn.Conv1d(1, 300, kernel_size=300, stride=1, padding=0)\n",
        "        self.bn3 = nn.BatchNorm1d(300)\n",
        "\n",
        "        self.fc1 = nn.Linear(300, 250)\n",
        "        self.bnfc1 = nn.BatchNorm1d(250)\n",
        "\n",
        "        # livedoorニュースの9カテゴリに対応するかな？と期待する9分類\n",
        "        self.fc2 = nn.Linear(250, 9)\n",
        "\n",
        "        # overclustering\n",
        "        # 実際の想定よりも多めにクラスタリングさせることで、ネットワークで微細な変化を捉えられるようにする\n",
        "        self.fc2_overclustering = nn.Linear(250, 9*OVER_CLUSTRING_RATE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), 1, -1)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        x = x.view(x.size(0), 1, -1)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "\n",
        "        x = x.view(x.size(0), 1, -1)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_prefinal = F.relu(self.bnfc1(self.fc1(x)))\n",
        "\n",
        "        # multi-headは使わず\n",
        "        y = F.softmax(self.fc2(x_prefinal), dim=1)\n",
        "        y_overclustering = F.softmax(self.fc2_overclustering(\n",
        "            x_prefinal), dim=1)  # overclustering\n",
        "\n",
        "        return y, y_overclustering\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGKmdx0Ux112"
      },
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "def weight_init(m):\n",
        "    \"\"\"重み初期化\"\"\"\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        # Xavier\n",
        "        # init.xavier_normal_(m.weight.data)\n",
        "\n",
        "        # He\n",
        "        init.kaiming_normal_(m.weight.data)\n",
        "\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnVaLHowOR_S"
      },
      "source": [
        "# IISによる損失関数の定義\n",
        "# 参考：https://github.com/RuABraun/phone-clustering/blob/master/mnist_basic.py\n",
        "import sys\n",
        "\n",
        "\n",
        "def compute_joint(x_out, x_tf_out):\n",
        "    bn, k = x_out.size()\n",
        "    assert (x_tf_out.size(0) == bn and x_tf_out.size(1) == k), '{} {} {} {}'.format(\n",
        "        bn, k, x_tf_out.size(0), x_tf_out.size(1))\n",
        "\n",
        "    p_i_j = x_out.unsqueeze(2) * x_tf_out.unsqueeze(1)  # bn, k, k\n",
        "    p_i_j = p_i_j.sum(dim=0)  # k, k\n",
        "    p_i_j = (p_i_j + p_i_j.t()) / 2.  # symmetrise\n",
        "    p_i_j = p_i_j / p_i_j.sum()  # normalise\n",
        "    return p_i_j\n",
        "\n",
        "\n",
        "def IID_loss(x_out, x_tf_out, EPS=sys.float_info.epsilon):\n",
        "    # has had softmax applied\n",
        "    bs, k = x_out.size()\n",
        "    p_i_j = compute_joint(x_out, x_tf_out)\n",
        "    assert (p_i_j.size() == (k, k))\n",
        "\n",
        "    p_i = p_i_j.sum(dim=1).view(k, 1).expand(k, k)\n",
        "    p_j = p_i_j.sum(dim=0).view(1, k).expand(k, k)\n",
        "\n",
        "    # avoid NaN losses. Effect will get cancelled out by p_i_j tiny anyway\n",
        "    # これはPyTorchのバージョン1.3以上だとエラーになる\n",
        "    # https://discuss.pytorch.org/t/pytorch-1-3-showing-an-error-perhaps-for-loss-computed-from-paired-outputs/68790/3\n",
        "    #p_i_j[(p_i_j < EPS).data] = EPS\n",
        "    #p_j[(p_j < EPS).data] = EPS\n",
        "    #p_i[(p_i < EPS).data] = EPS\n",
        "\n",
        "    p_i_j = torch.where(p_i_j < EPS, torch.tensor(\n",
        "        [EPS], device=p_i_j.device), p_i_j)\n",
        "    p_j = torch.where(p_j < EPS, torch.tensor([EPS], device=p_j.device), p_j)\n",
        "    p_i = torch.where(p_i < EPS, torch.tensor([EPS], device=p_i.device), p_i)\n",
        "\n",
        "    # https://qiita.com/Amanokawa/items/0aa24bc396dd88fb7d2a\n",
        "    # 参考に、重みalphaを追加\n",
        "\n",
        "    alpha = 2.0\n",
        "    loss = (- p_i_j * (torch.log(p_i_j) - alpha *\n",
        "                       torch.log(p_j) - alpha*torch.log(p_i))).sum()\n",
        "\n",
        "    return loss\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbX7HxheOWIp"
      },
      "source": [
        "# データにノイズを加える関数の定義\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tensor_std = list_text_train.std(dim=0).to(device)\n",
        "\n",
        "\n",
        "def perturb_data(x):\n",
        "    y = x.clone()\n",
        "    noise = torch.randn(len(tensor_std)).to(device)*tensor_std*2.0\n",
        "    noise = noise.expand(x.shape[0], -1)\n",
        "    y += noise\n",
        "\n",
        "    return y\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt1jf4xAz0r4"
      },
      "source": [
        "## 4：IICのネットワークを学習させる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em2zsT9jOSDC"
      },
      "source": [
        "# 学習関数の定義\n",
        "\n",
        "def train(total_epoch, model, train_loader, optimizer, device):\n",
        "\n",
        "    # ネットワークを訓練モードに\n",
        "    model.train()\n",
        "\n",
        "    # 学習率のスケジューラーCosAnnealing\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=2, T_mult=2, eta_min=0)\n",
        "\n",
        "    for epoch in range(total_epoch):\n",
        "        for batch_idx, (target, data) in enumerate(train_loader):\n",
        "\n",
        "            # 学習率変化\n",
        "            scheduler.step()\n",
        "            \n",
        "            data_perturb = perturb_data(data)  # ノイズを与え、変換したデータを作る\n",
        "\n",
        "            # GPUに送れる場合は送る\n",
        "            data = data.to(device)\n",
        "            data_perturb = data_perturb.to(device)\n",
        "\n",
        "            # 最適化関数の初期化\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # ニューラルネットワークへ入れる\n",
        "            output, output_overclustering = model(data)\n",
        "            output_perturb, output_perturb_overclustering = model(data_perturb)\n",
        "\n",
        "            # 損失の計算\n",
        "            loss1 = IID_loss(output, output_perturb)\n",
        "            loss2 = IID_loss(output_overclustering,\n",
        "                             output_perturb_overclustering)\n",
        "            loss = loss1 + loss2\n",
        "\n",
        "            # 損失を減らすように更新\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # ログ出力\n",
        "        if epoch % 50 == 0:\n",
        "            print('Train Epoch {} \\tLoss1: {:.6f} \\tLoss2: {:.6f} \\tLoss_total: {:.6f}'.format(\n",
        "                epoch, loss1.item(), loss2.item(), loss1.item()+loss2.item()))\n",
        "\n",
        "    return model, optimizer\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNVviRq-0-wH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfddaf5-6590-4456-ae68-b7ab4aa0e772"
      },
      "source": [
        "# 学習の実施(5分弱)\n",
        "\n",
        "# モデルの用意\n",
        "net = NetIIC()\n",
        "net.apply(weight_init)\n",
        "net.to(device)\n",
        "\n",
        "# 最適化関数\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4) \n",
        "\n",
        "total_epoch = 1000\n",
        "\n",
        "model_trained, optimizer = train(\n",
        "    total_epoch, net, dl_bert_train, optimizer, device)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 0 \tLoss1: -3.945977 \tLoss2: -7.733891 \tLoss_total: -11.679867\n",
            "Train Epoch 50 \tLoss1: -6.163636 \tLoss2: -10.227787 \tLoss_total: -16.391423\n",
            "Train Epoch 100 \tLoss1: -6.519540 \tLoss2: -11.245013 \tLoss_total: -17.764553\n",
            "Train Epoch 150 \tLoss1: -6.554135 \tLoss2: -11.682366 \tLoss_total: -18.236502\n",
            "Train Epoch 200 \tLoss1: -6.559808 \tLoss2: -12.294264 \tLoss_total: -18.854072\n",
            "Train Epoch 250 \tLoss1: -6.540496 \tLoss2: -12.461839 \tLoss_total: -19.002335\n",
            "Train Epoch 300 \tLoss1: -6.548514 \tLoss2: -13.140853 \tLoss_total: -19.689367\n",
            "Train Epoch 350 \tLoss1: -6.542245 \tLoss2: -13.114568 \tLoss_total: -19.656813\n",
            "Train Epoch 400 \tLoss1: -6.576515 \tLoss2: -13.155249 \tLoss_total: -19.731764\n",
            "Train Epoch 450 \tLoss1: -6.554772 \tLoss2: -13.119078 \tLoss_total: -19.673850\n",
            "Train Epoch 500 \tLoss1: -6.567766 \tLoss2: -13.148041 \tLoss_total: -19.715806\n",
            "Train Epoch 550 \tLoss1: -6.571950 \tLoss2: -13.201900 \tLoss_total: -19.773850\n",
            "Train Epoch 600 \tLoss1: -6.545648 \tLoss2: -13.169672 \tLoss_total: -19.715320\n",
            "Train Epoch 650 \tLoss1: -6.542305 \tLoss2: -13.169475 \tLoss_total: -19.711780\n",
            "Train Epoch 700 \tLoss1: -6.553681 \tLoss2: -13.200727 \tLoss_total: -19.754409\n",
            "Train Epoch 750 \tLoss1: -6.572183 \tLoss2: -13.099102 \tLoss_total: -19.671285\n",
            "Train Epoch 800 \tLoss1: -6.573242 \tLoss2: -13.154708 \tLoss_total: -19.727950\n",
            "Train Epoch 850 \tLoss1: -6.561141 \tLoss2: -13.122187 \tLoss_total: -19.683327\n",
            "Train Epoch 900 \tLoss1: -6.570803 \tLoss2: -13.200661 \tLoss_total: -19.771463\n",
            "Train Epoch 950 \tLoss1: -6.571137 \tLoss2: -13.157137 \tLoss_total: -19.728274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdxKZzijT5PG"
      },
      "source": [
        "# モデル分類のクラスターの結果を確認する\n",
        "import numpy as np\n",
        "\n",
        "# ミニバッチサイズ1のテスト用のDataLoaderを用意\n",
        "dl_bert_test = DataLoader(\n",
        "    dataset_bert_test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    out_targs = []\n",
        "    ref_targs = []\n",
        "\n",
        "    # 出力用のリストを用意\n",
        "    total_num = len(test_loader)\n",
        "    # index, (target_label, inferenced_label)\n",
        "    output_list = np.zeros((total_num, 2))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (target, data) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            outputs, outputs_overclustering = model(data)\n",
        "\n",
        "            # 分類結果をリストに追加\n",
        "            out_targs.append(outputs.argmax(dim=1).cpu())\n",
        "            ref_targs.append(target[0].cpu())\n",
        "\n",
        "            # 結果をリストにまとめる\n",
        "            output_list[batch_idx, 0] = target[0][0].cpu()  # 正解ラベル\n",
        "            output_list[batch_idx, 1] = outputs.argmax(dim=1).cpu()  # 予測ラベル\n",
        "\n",
        "    out_targs = torch.cat(out_targs)\n",
        "    ref_targs = torch.cat(ref_targs)\n",
        "\n",
        "    return out_targs.view(-1, 1).numpy(), ref_targs.numpy(), output_list\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpX0jnIRBmsT"
      },
      "source": [
        "# テストデータで推論を実施\n",
        "out_targs, ref_targs, output_list = test(model_trained, device, dl_bert_test)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F0HrySbC_RI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1700d603-ebaa-4af9-bd52-95634e72eb5f"
      },
      "source": [
        "# 混同行列（的な）を作る\n",
        "matrix = np.zeros((9, 9))\n",
        "\n",
        "# 縦にlivedoorニュースの正解クラスを、横に判定されたクラスの頻度表を作成\n",
        "for i in range(len(out_targs)):\n",
        "    row = ref_targs[i]\n",
        "    col = out_targs[i]\n",
        "    matrix[row][col] += 1\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "print(matrix)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  7.   6.  15.   1.  36.   8.  13.   4.  16.]\n",
            " [ 25.   0.  63.  25.  18.  19.  28.   4.   3.]\n",
            " [ 26.   1.   0.   0.   2.  44.   1.  75.   2.]\n",
            " [  4. 128.   1.   2.   5.   3.   8.  11.   2.]\n",
            " [  7.   0.   5.  93.   7.  13.  37.   0.   2.]\n",
            " [ 58.   1.   0.   0.   5.  53.   1.  62.   1.]\n",
            " [  3.   6.   1.   0.  16.   1.   1.   4. 140.]\n",
            " [ 13.  13.  12.   1.  48.   9.  49.   4.  26.]\n",
            " [ 58.   3.  21.   8.  12.  46.  20.   3.   6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VOxWCCG4VM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ae0836-e22b-4944-9f3d-ef27d9809316"
      },
      "source": [
        "dic_id2cat\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'livedoor-homme',\n",
              " 1: 'it-life-hack',\n",
              " 2: 'topic-news',\n",
              " 3: 'movie-enter',\n",
              " 4: 'smax',\n",
              " 5: 'sports-watch',\n",
              " 6: 'dokujo-tsushin',\n",
              " 7: 'peachy',\n",
              " 8: 'kaden-channel'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCc4YyVLH3JW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ae9d7724-27f3-4618-d965-c404083d6f56"
      },
      "source": [
        "# クラスタの結果を確認\n",
        "#「sports-watch」の5番目のクラスタの文章、7番目のクラスタの文章\n",
        "#「topic-news」の5番目のクラスタの文章、7番目のクラスタの文章\n",
        "# を確認して、クラスタ5とクラスタ7の特徴を見てみます。\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df2 = pd.DataFrame(output_list)\n",
        "df2.columns=[\"正解クラス\", \"推定クラスタ\"]\n",
        "df2.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   正解クラス  推定クラスタ\n",
              "0    5.0     5.0\n",
              "1    6.0     8.0\n",
              "2    3.0     6.0\n",
              "3    6.0     8.0\n",
              "4    5.0     7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMeY6zIIKpPT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0972fa24-8cf9-447c-a61f-15990a02e35a"
      },
      "source": [
        "df2[(df2['正解クラス']==0) & (df2['推定クラスタ']==5)].head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>678</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>812</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1046</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      正解クラス  推定クラスタ\n",
              "29      0.0     5.0\n",
              "568     0.0     5.0\n",
              "678     0.0     5.0\n",
              "812     0.0     5.0\n",
              "1046    0.0     5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cZdu5D-MClM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8352f495-ac30-4754-db89-ddedf854c6e4"
      },
      "source": [
        "# dfに元文書を入れている。300文字ほど見る。\n",
        "print(df.iloc[21, 0][:300])\n",
        "print(df.iloc[59, 0][:300])\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "こんにちは、「ビズリーチ年収1000万円研究所」所長の佐藤和男です。この研究所では、年収1000万円以上のビジネスパーソンに対してさまざまなアンケートを取り、“年収1000万円を稼ぐビジネスパーソンの考え方”を調査しています。今回のご報告は、経験豊富なビジネスパーソンが就職活動中の大学生にお勧めしたい「本当の企業ランキング」。長引く不況で就職氷河期と言われる昨今、就職するならぜひ目指して欲しいと思う企業のアンケートを行いました。年収1000万円のビジネスパーソンは、どんな企業を選ぶのか——。共通する傾向を探りました。Q1.就職活動中の大学生にお勧めしたい就職先企業を3社まで挙げてください。1位\n",
            "日常の何気ない気持ちをTwitterにつぶやいたり、実名登録のFacebookで懐かしい友人と再会したり、SNSはもはや我々の生活において欠かせない存在となりつつある。先日、国内の月間利用者数が1,000万人を突破し、mixi（1,520万人、2011年12月現在）を追い抜くのも時間の問題と思われるFacebookでは、診断やゲームなど様々なアプリが生まれ、ユーザーのタイムラインを今日も賑わしている。しかし、その一方で、Facebookを悪用するケースもまた徐々に増え始めている。Facebookでは、2008年1月にAPIが公開されて以来、様々なアプリが誕生しているが、同年8月にはボット型の不\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inah7FkKOjGD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "cfefde74-9b8d-44c2-9e21-08b2fb037091"
      },
      "source": [
        "df2[(df2['正解クラス']==0) & (df2['推定クラスタ']==7)].head(2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     正解クラス  推定クラスタ\n",
              "185    0.0     7.0\n",
              "495    0.0     7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmyvw1rIOo9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6254050b-cad6-4946-8fdd-8959cf8f6516"
      },
      "source": [
        "# dfに元文書を入れている。300文字ほど見る。\n",
        "print(df.iloc[14, 0][:300])\n",
        "print(df.iloc[18, 0][:300])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "◆プロフィール小沢コージバブル期にソアラ、プレリュードを横目で眺め、トレンディドラマを見、合コンしまくったスーパーカーブームど真ん中イケメン自動車ジャーナリスト。現在『BESTCAR』『ENGINE』『DIME』誌ほか『webCG』『日経TRENDY』『carview』などwebでも大活躍！吉田由美当時、ミスコン荒らしとして20コ以上のミスの肩書きを持ち、某専門誌「○×のすべて」に助手席モデルとして君臨。「経歴は編集長より長いかも（笑）」（本人談）という業界きっての謎の美女。今はカーライフエッセイストの名のもと「ブログの女王」として自動車メディアはもちろんファッション誌に無くてはならない存在と\n",
            "現在はMacRumors（Macのうわさ）というサイトでしか見ることができないが、6日ほど前にKitGuruというサイトが中国のiPhoneケースベンダーに持ち込まれたという「iPhone 5のモックアップ」と称する写真を掲載していた（ちなみに現在はどこからかの強い圧力のため削除されている模様）。このモックアップがホンモノであることを証明するかのように、楽天市場などのショッピングサイトで「iPhone 5用ケース先行販売」という形でケースが販売されている。「iPhone 5 ケース」での検索結果検索された商品のページ。何と購入可能。試しに楽天で「iPhone 5 ケース」というキーワードで検索\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j38ZwfvuO3lC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "24d4fc72-b1c8-443b-c3e3-e6e5879e873c"
      },
      "source": [
        "df2[(df2['正解クラス']==8) & (df2['推定クラスタ']==5)].head(2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    正解クラス  推定クラスタ\n",
              "55    8.0     5.0\n",
              "65    8.0     5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_EFqTeyPCwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab196325-4ed6-40b7-fc5d-c6914d15a9b1"
      },
      "source": [
        "# dfに元文書を入れている。300文字ほど見る。\n",
        "print(df.iloc[7, 0][:300])\n",
        "print(df.iloc[55, 0][:300])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AKB48の篠田麻里子のツイッターが人気だ。じゃんけん大会で優勝しセンターを射止めて以来さらに注目されている彼女。ツイッターでメンバーからもらったお土産を紹介し話題になっている。写真付きで紹介されたツイートはこちら。ちなみにニャロから敦子へのお土産は コチラ！！！！ 『あっちゃんに似てるー(((бвб))』 って言ってたよ（笑） ……(´∵`)ノあっちゃんもびっくりだ〜一緒に添付されている画像は、確かに前田敦子に似ていると言えなくもない女性の裸体をモチーフにしたお土産。そして、そのお土産よりも衝撃なのは篠田麻里子が前田敦子に選んだ顔文字だ。以前より、前田敦子はタモリなどにも番組で顔のパーツが中\n",
            "NHN Japanは、同社が提供する「livedoorニュース」で配信している記事の中から、IT記事に特化したニュースをまとめて閲覧することができるスマートフォンアプリ「ITニュース by livedoor ニュース」（iOS・Android対応／無料）を公開している。好きなジャンルの情報を逃さない向かうところ敵なしのITニュースリーダーだ。というのも、このアプリではlivedoorニュースの編集部が厳選したIT記事が提供されるが、編集部の手作業によって「ITビジネス」「WEBサービス」「マーケティング」「モバイル」「デジタル家電」などの12のカテゴリに振り分けられるので、数ある情報の中から興\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc6hzsl4PC1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "e63668bc-a680-46e2-b5d9-ad7b5e4c385d"
      },
      "source": [
        "df2[(df2['正解クラス']==8) & (df2['推定クラスタ']==7)].head(2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>正解クラス</th>\n",
              "      <th>推定クラスタ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     正解クラス  推定クラスタ\n",
              "546    8.0     7.0\n",
              "692    8.0     7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCTytj5TPC4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb448eca-8368-4a66-ef94-9a415bca50c3"
      },
      "source": [
        "# dfに元文書を入れている。300文字ほど見る。\n",
        "print(df.iloc[71, 0][:300])\n",
        "print(df.iloc[76, 0][:300])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "フィクションの中だけだと思われていた技術が、次々と現実化している。MITメディアラボの研究グループが開発に成功したのは、何と曲がり角の先を撮影することのできるカメラだ。光ファイバーを伸ばして曲がり角の先の様子を確認することなら今の技術でもできるわけだが、MITメディアラボが開発したのはそういうものではない。曲がり角から離れた位置、つまり角を曲がる前に先の様子を撮影できるのだ。この技術のポイントは、レーザーを使うことにある。カメラに設置されたレーザー発振装置からレーザーパルスが発射され、カメラから見える位置にある壁にぶつかる。レーザー光は、壁にぶつかって飛び散り、いくつかはカメラから見えない位置\n",
            "ＮＨＫは４月に民放大手５社と電通が進めているインターネットテレビ事業へ参入するという方針を固めた。これは、通常放送のほかに過去の番組約１万本を視聴できるようにするというものだ。深刻化するテレビ離れを食い止める狙いだという。過去番組１万本のうち、NHKが所有するのは４０００本程度になるとみられる。ネット上では「NHKも参加するんだ」という驚きの声や「おもしろい番組があれば見る」といったコメントが寄せられている。もちろんラインナップや仕組みにもよるが、過去のものを豊富に見ることができる環境ができることで今までとは違ったテレビ生活が生まれそうだ。ＮＨＫ、ネットテレビ参入４月、民放計画に合流■関連記事\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1hvCYcuRLzF"
      },
      "source": [
        "文章を見ただけでは、あまり特徴は分かりませんね。。。\n",
        "\n",
        "ただ、スポーツとニュースは、記事の雰囲気がとても似ていることは分かります。\n",
        "\n",
        "これ以上に、IICされたクラスタの特徴をきちんと把握するには、\n",
        "\n",
        "- wordcloudで単語の頻度の傾向を見てみる\n",
        "- クラスタ文書の全ベクトルをいじいじして、なんらかクラスタのベクトルを作って、代表文書を決めたり近い単語を出す\n",
        "\n",
        "などの操作が考えられます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y37pHqN2YD0"
      },
      "source": [
        "以上。"
      ]
    }
  ]
}